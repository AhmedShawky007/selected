{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2adhEx4ljqE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "fNgvoH_zl5_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_PATH=\"/content/drive/MyDrive/Selected 1 pro/Churn_Modelling.csv\"\n",
        "# Importing data into python from the given csv file\n",
        "dataset= pd.read_csv(NUM_PATH)\n"
      ],
      "metadata": {
        "id": "W2ixhA1AnZAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "z_4EUPlwn_Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.tail()"
      ],
      "metadata": {
        "id": "mVtvJ16aoKrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.dtypes"
      ],
      "metadata": {
        "id": "96bn0Q_Coc1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "tHzCXZK5op2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns"
      ],
      "metadata": {
        "id": "egbs8imKo70_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.describe()"
      ],
      "metadata": {
        "id": "yTbKmHk_41Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.CreditScore.value_counts()"
      ],
      "metadata": {
        "id": "oJ7Hi-gr45CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.CreditScore.isna().any()"
      ],
      "metadata": {
        "id": "SwgZ-GHd5Bwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.drop(labels=['CustomerId','Surname'],\n",
        "                axis=1,\n",
        "                inplace=True)\n"
      ],
      "metadata": {
        "id": "qBRm3kDB5JUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "InUJiYH25QT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.Geography.value_counts(dropna=False)"
      ],
      "metadata": {
        "id": "-38ULnb35VzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.Gender.value_counts(dropna=False)"
      ],
      "metadata": {
        "id": "gvDy4XWu5dg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_cleaned = pd.get_dummies(dataset, \n",
        "                                    prefix=['Geo','Gen'], \n",
        "                                    prefix_sep='_',\n",
        "                                    dummy_na=False, \n",
        "                                    columns=['Geography','Gender'],\n",
        "                                    sparse=False,\n",
        "                                    drop_first=False,\n",
        "                                    dtype=int) "
      ],
      "metadata": {
        "id": "dhQjCWYa5k0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_cleaned"
      ],
      "metadata": {
        "id": "iP6RdhXd57o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.isna().any()"
      ],
      "metadata": {
        "id": "ugS4G9uU7Lei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.corr()"
      ],
      "metadata": {
        "id": "csY4xgEH-MJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_cleaned.hist(bins=10,\n",
        "                        figsize=(20,20),\n",
        "                        xrot=30)"
      ],
      "metadata": {
        "id": "unGmYRTc-UOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "_gtmsEty-yYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=dataset_cleaned.columns\n",
        "print(labels)\n",
        "scaler=preprocessing.StandardScaler()\n",
        "scaled_dataset_cleaned=scaler.fit_transform(dataset_cleaned)"
      ],
      "metadata": {
        "id": "OlOQIyz1-iEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_dataset_cleaned=pd.DataFrame(scaled_dataset_cleaned)\n",
        "scaled_dataset_cleaned.columns=labels"
      ],
      "metadata": {
        "id": "B3q3s7yy_C1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_dataset_cleaned.hist(bins=10,\n",
        "                               figsize=(20,20),\n",
        "                               xrot=30)"
      ],
      "metadata": {
        "id": "8Wzqxk0W_TTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(1,1,figsize=(20,20))\n",
        "for i in scaled_dataset_cleaned.columns:\n",
        "    sns.kdeplot(scaled_dataset_cleaned[i],\n",
        "                 label=[i],\n",
        "                 bw=1.5,\n",
        "                 ax=ax)"
      ],
      "metadata": {
        "id": "HUw_RBAt_ZfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr=scaled_dataset_cleaned.corr()"
      ],
      "metadata": {
        "id": "D4JfxYSJ_4xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(1,1,figsize=(20,10))\n",
        "sns.heatmap(corr,\n",
        "            annot=True,\n",
        "            cmap='RdYlGn',\n",
        "            ax=ax)"
      ],
      "metadata": {
        "id": "c-XtFlRNABNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nr=7\n",
        "nc=2\n",
        "fig,ax=plt.subplots(nrows=nr,ncols=nc,figsize=(20,20))\n",
        "i=0\n",
        "for j in range(nr):\n",
        "    for k in range(nc):\n",
        "        axes=ax[j,k]\n",
        "        \n",
        "        sns.boxplot(x=scaled_dataset_cleaned['Exited'],\n",
        "                    y=scaled_dataset_cleaned.iloc[:,i],\n",
        "                    ax=axes)\n",
        "        i+=1"
      ],
      "metadata": {
        "id": "ZRJhQZX3AFPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_dataset_cleaned=scaled_dataset_cleaned.drop('Exited',\n",
        "                                                         axis=1)"
      ],
      "metadata": {
        "id": "ekG5d_auKSSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_dataset_cleaned.columns"
      ],
      "metadata": {
        "id": "vuqkCa0-A0jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "n_comp = 2\n",
        "pca=PCA(n_components=n_comp)\n",
        "principal_components=pca.fit_transform(scaled_dataset_cleaned)\n",
        "len(principal_components)\n"
      ],
      "metadata": {
        "id": "1Drh6-FSKc1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc_df=pd.DataFrame(principal_components,\n",
        "                  columns=['principal_components_%s'%(i+1) for i in range(n_comp)],\n",
        "                  index=range(1,len(principal_components)+1))\n",
        "print(pc_df)"
      ],
      "metadata": {
        "id": "5fhNda0EKvja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_components=pc_df\n",
        "output_components=dataset.Exited\n",
        "print(input_components.shape,output_components.shape)\n",
        "final_df=pd.concat([input_components,output_components],axis=1)"
      ],
      "metadata": {
        "id": "1NaLmvPTK0HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(1,1,figsize=(20,20))\n",
        "ax.set_xlabel('principal_components_1',fontsize=20)\n",
        "ax.set_ylabel('principal_components_2',fontsize=20)\n",
        "ax.set_title('Customers Exited on PC1 & PC2',fontsize=20)\n",
        "\n",
        "Targets=[0,1]\n",
        "colors=['r','k']\n",
        "\n",
        "for target,color in zip(Targets,colors):\n",
        "    index_no_target=final_df['Exited']==target\n",
        "    ax.scatter(final_df.loc[index_no_target,'principal_components_1'],\n",
        "               final_df.loc[index_no_target,'principal_components_2'],\n",
        "              c=color)\n",
        "    ax.legend(Targets)\n",
        "    ax.grid()"
      ],
      "metadata": {
        "id": "swYgBafDK74x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "3YZMVPihLCJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_comp=10\n",
        "pca_10=PCA(n_components=n_comp)\n",
        "pca10_comp=pca_10.fit_transform(scaled_dataset_cleaned)\n",
        "df_PCA_10=pd.DataFrame(pca10_comp,\n",
        "                       columns=['Principal_component_%s'%(i+1) for i in range(n_comp)],\n",
        "                      index=range(1,len(pca10_comp)+1))\n",
        "print(df_PCA_10)"
      ],
      "metadata": {
        "id": "2Vp8fw9fLHJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(pca_10.explained_variance_ratio_)"
      ],
      "metadata": {
        "id": "BEY24RKVLO3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Train split of the datdset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_PCA_10,\n",
        "                                               output_components, test_size=0.2, random_state=44, shuffle =True)"
      ],
      "metadata": {
        "id": "CwW_ZfXHLTDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Applying LogisticRegression Model \n",
        "\n",
        "'''\n",
        "#linear_model.LogisticRegression(penalty='l2’,dual=False,tol=0.0001,C=1.0,fit_intercept=True,intercept_scaling=1,\n",
        "#                                class_weight=None,random_state=None,solver='warn’,max_iter=100,\n",
        "#                                multi_class='warn’, verbose=0,warm_start=False, n_jobs=None)\n",
        "'''\n",
        "\n",
        "LogisticRegressionModel = LogisticRegression(penalty='l1',solver='',C=1., n_jobs=None,max_iter=1000 )\n",
        "\n",
        "LogisticRegressionModel.fit(x_train, y_train)\n",
        "\n",
        "print('LogisticRegressionModel Train Score is : ' , LogisticRegressionModel.score(x_train, y_train))\n",
        "print('LogisticRegressionModel Test Score is : ' , LogisticRegressionModel.score(x_test, y_test))\n",
        "print('LogisticRegressionModel Classes are : ' , LogisticRegressionModel.classes_)\n",
        "print('LogisticRegressionModel No. of iteratios is : ' , LogisticRegressionModel.n_iter_)\n",
        "print('----------------------------------------------------')\n",
        "#Calculating Prediction\n",
        "y_pred = LogisticRegressionModel.predict(x_test)\n",
        "y_pred_prob = LogisticRegressionModel.predict_proba(x_test)\n",
        "print('Predicted Value for LogisticRegressionModel is : ' , y_pred[:1000])\n",
        "print('Prediction Probabilities Value for LogisticRegressionModel is : ' , y_pred_prob[:10])\n",
        "\n",
        "#----------------------------------------------------\n",
        "#Calculating Accuracy Score  : ((TP + TN) / float(TP + TN + FP + FN))\n",
        "AccScore = accuracy_score(y_test, y_pred, normalize=True)\n",
        "print('Accuracy Score is : ', AccScore)\n",
        "\n",
        "#----------------------------------------------------\n",
        "#Calculating Precision Score : (Specificity) #(TP / float(TP + FP))  \n",
        "# precision_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’,sample_weight=None)\n",
        "\n",
        "PrecisionScore = precision_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\n",
        "print('Precision Score is : ', PrecisionScore)\n",
        "\n",
        "\n",
        "#----------------------------------------------------\n",
        "#Calculating F1 Score  : 2 * (precision * recall) / (precision + recall)\n",
        "# f1_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)\n",
        "\n",
        "F1Score = f1_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\n",
        "print('F1 Score is : ', F1Score)\n",
        "\n",
        "#----------------------------------------------------\n",
        "#Calculating Confusion Matrix\n",
        "CM = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix is : \\n', CM)\n",
        "\n",
        "# drawing confusion matrix\n",
        "sns.heatmap(CM, center = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-viy2rx9TtJv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}